{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EDA on restuarant_videos.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "36a64333ec4f4d249df1bdb8b9c9772b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ecbcf48ea62f4e8099e109b9744b7710",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_972bc801afe24182af9e548443b47532",
              "IPY_MODEL_8528f700dca44d988b50dfe6c8fb1f16"
            ]
          }
        },
        "ecbcf48ea62f4e8099e109b9744b7710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "972bc801afe24182af9e548443b47532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3f50ae49714a47ad8834602607f53564",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 277138115,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 277138115,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_99a3bc24e327442ea391b1fa4610f4dc"
          }
        },
        "8528f700dca44d988b50dfe6c8fb1f16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a35e2700d43486ab75864478488ae84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 264M/264M [00:04&lt;00:00, 60.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73d383af7ebb4a9b82ddabe0da1905e3"
          }
        },
        "3f50ae49714a47ad8834602607f53564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "99a3bc24e327442ea391b1fa4610f4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a35e2700d43486ab75864478488ae84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73d383af7ebb4a9b82ddabe0da1905e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cul7g0epwBq_"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Video_grouping_results/VideoGroupingProject\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxNgRdZmYwet"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ8Lxpek2Nz-",
        "outputId": "682bf851-1bc6-4dc9-dd64-58ff14914f89"
      },
      "source": [
        "!pip install \"git+https://github.com/facebookresearch/pytorchvideo.git\"\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/facebookresearch/pytorchvideo.git\n",
            "  Cloning https://github.com/facebookresearch/pytorchvideo.git to /tmp/pip-req-build-nc9mmpkf\n",
            "  Running command git clone -q https://github.com/facebookresearch/pytorchvideo.git /tmp/pip-req-build-nc9mmpkf\n",
            "Collecting fvcore>=0.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/21/95fe7a6fd178bccdfe1af37b30737fcc1d0454314936dab503d3c3ee033b/fvcore-0.1.5.post20210604.tar.gz (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hCollecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/ff/bacde7314c646a2bd2f240034809a10cc3f8b096751284d0828640fff3dd/av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 78kB/s \n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading https://files.pythonhosted.org/packages/31/13/fe468c8c7400a8eca204e6e160a29bf7dcd45a76e20f1c030f3eaa690d93/parameterized-0.8.1-py2.py3-none-any.whl\n",
            "Collecting iopath\n",
            "  Downloading https://files.pythonhosted.org/packages/21/d0/22104caed16fa41382702fed959f4a9b088b2f905e7a82e4483180a2ec2a/iopath-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.4->pytorchvideo==0.1.1) (1.19.5)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Collecting pyyaml>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.4->pytorchvideo==0.1.1) (4.41.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.4->pytorchvideo==0.1.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.4->pytorchvideo==0.1.1) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fvcore>=0.1.4->pytorchvideo==0.1.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pytorchvideo, fvcore\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.1-cp37-none-any.whl size=155238 sha256=832cee96868d246deb9e9b49a011df23ccc997bbe433824137b1eb3b0c48b0bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-zsj2qxef/wheels/56/74/10/f3f9925bf7096f72530ef877ce52dab12f4c00486990bd7e32\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20210604-cp37-none-any.whl size=60475 sha256=a61cff8407c4d1c13cd4425b142a4846ec891b79ce4fe04cf7fc048ea911f359\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/e3/fb/2d4b0c12020f6e4535c2a8fb2da9b6b17cf9f03efd4e542ffc\n",
            "Successfully built pytorchvideo fvcore\n",
            "Installing collected packages: pyyaml, yacs, portalocker, iopath, fvcore, av, parameterized, pytorchvideo\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed av-8.0.3 fvcore-0.1.5.post20210604 iopath-0.1.8 parameterized-0.8.1 portalocker-2.3.0 pytorchvideo-0.1.1 pyyaml-5.4.1 yacs-0.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eganvKU3Qcw"
      },
      "source": [
        "import glob\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import cv2\n",
        "import math \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHXP75XV4k7K"
      },
      "source": [
        "#Pytroch Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1Y_3mK2Y7m"
      },
      "source": [
        "import torch\n",
        "import json\n",
        "from torchvision.transforms import Compose, Lambda\n",
        "from torchvision.transforms._transforms_video import (\n",
        "    CenterCropVideo,\n",
        "    NormalizeVideo,\n",
        ")\n",
        "from pytorchvideo.data.encoded_video import EncodedVideo\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    ShortSideScale,\n",
        "    UniformTemporalSubsample,\n",
        "    UniformCropVideo\n",
        ")\n",
        "from typing import Dict\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1wHuT6A-4hP",
        "outputId": "f7d53846-dde4-44eb-df51-b23f0a0ff3e8"
      },
      "source": [
        "print(torch.__version__\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "36a64333ec4f4d249df1bdb8b9c9772b",
            "ecbcf48ea62f4e8099e109b9744b7710",
            "972bc801afe24182af9e548443b47532",
            "8528f700dca44d988b50dfe6c8fb1f16",
            "3f50ae49714a47ad8834602607f53564",
            "99a3bc24e327442ea391b1fa4610f4dc",
            "4a35e2700d43486ab75864478488ae84",
            "73d383af7ebb4a9b82ddabe0da1905e3"
          ]
        },
        "id": "INhfkBtB4FCN",
        "outputId": "8649d31a-1493-4081-983a-5becf2dfaf8c"
      },
      "source": [
        "# Device on which to run the model\n",
        "# Set to cuda to load on GPU\n",
        "device = \"cuda\"\n",
        "\n",
        "# Pick a pretrained model and load the pretrained weights\n",
        "model_name = \"slowfast_r50\"\n",
        "model = torch.hub.load(\"facebookresearch/pytorchvideo\", model=model_name, pretrained=True)\n",
        "\n",
        "# Set to eval mode and move to desired device\n",
        "model = model.to(device)\n",
        "model = model.eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/pytorchvideo/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/pytorchvideo/model_zoo/kinetics/SLOWFAST_8x8_R50.pyth\" to /root/.cache/torch/hub/checkpoints/SLOWFAST_8x8_R50.pyth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36a64333ec4f4d249df1bdb8b9c9772b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=277138115.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYldlPf04x6Q",
        "outputId": "537026ea-8da1-4d83-d916-139a0de51851"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-08 01:35:57--  https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10326 (10K) [text/plain]\n",
            "Saving to: ‘kinetics_classnames.json’\n",
            "\n",
            "\rkinetics_classnames   0%[                    ]       0  --.-KB/s               \rkinetics_classnames 100%[===================>]  10.08K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-08 01:35:57 (95.9 MB/s) - ‘kinetics_classnames.json’ saved [10326/10326]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B15CI1dB4yc2"
      },
      "source": [
        "with open(\"kinetics_classnames.json\", \"r\") as f:\n",
        "    kinetics_classnames = json.load(f)\n",
        "\n",
        "# Create an id to label name mapping\n",
        "kinetics_id_to_classname = {}\n",
        "for k, v in kinetics_classnames.items():\n",
        "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRMkfMtVor2b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xdi_mWu544dQ"
      },
      "source": [
        "####################\n",
        "# SlowFast transform\n",
        "####################\n",
        "\n",
        "side_size = 256\n",
        "mean = [0.45, 0.45, 0.45]\n",
        "std = [0.225, 0.225, 0.225]\n",
        "crop_size = 256\n",
        "alpha = 4\n",
        "\n",
        "class PackPathway(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Transform for converting video frames as a list of tensors.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, frames: torch.Tensor):\n",
        "        fast_pathway = frames\n",
        "        # Perform temporal sampling from the fast pathway.\n",
        "        slow_pathway = torch.index_select(\n",
        "            frames,\n",
        "            1,\n",
        "            torch.linspace(\n",
        "                0, frames.shape[1] - 1, frames.shape[1] // alpha\n",
        "            ).long(),\n",
        "        )\n",
        "        frame_list = [slow_pathway, fast_pathway]\n",
        "        return frame_list\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YStn6X1z96-8"
      },
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI_KvAw_5hNY",
        "outputId": "c9fdbe0c-2c69-4511-e0a8-eb3b52dc872c"
      },
      "source": [
        "# Load the example video\n",
        "\n",
        "tagsdict = dict() \n",
        "\n",
        "alltagsdict = dict()\n",
        "\n",
        "for videoname in os.listdir(path)[:1]:\n",
        "\n",
        "  video_path = path + \"/\" + videoname\n",
        "  \n",
        "  print(\"VideoName {0} :\".format(videoname))\n",
        "\n",
        "  cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "\n",
        "  total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "  #sampling_rate = 2\n",
        "  frames_per_second = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "  seconds = int(total_frames / frames_per_second)\n",
        "\n",
        "  print(\"Total clip duration \", seconds)\n",
        "\n",
        "  cap.release()\n",
        "\n",
        "  num_frames = 32\n",
        "  sampling_rate = 2\n",
        "  #frames_per_second = 30\n",
        "\n",
        "  #print(num_frames ,  frames_per_second)\n",
        "\n",
        "\n",
        "  # The duration of the input clip is also specific to the model.\n",
        "  clip_duration = (num_frames * sampling_rate)/frames_per_second\n",
        "\n",
        "  transform =  ApplyTransformToKey(\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(num_frames),\n",
        "            Lambda(lambda x: x/255.0),\n",
        "            NormalizeVideo(mean, std),\n",
        "            ShortSideScale(\n",
        "                size=side_size\n",
        "            ),\n",
        "            CenterCropVideo(crop_size),\n",
        "            PackPathway()\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "  \n",
        "\n",
        "  videotransform =  ApplyTransformToKey(\n",
        "    key=\"video\",\n",
        "    transform=Compose(\n",
        "        [\n",
        "            UniformTemporalSubsample(num_frames),\n",
        "            ShortSideScale(\n",
        "                size=side_size\n",
        "            ),\n",
        "            CenterCropVideo(crop_size),\n",
        "            PackPathway()\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "  #defaultdict(list)\n",
        "\n",
        "  # Select the duration of the clip to load by specifying the start and end duration\n",
        "  # The start_sec should correspond to where the action occurs in the video\n",
        " \n",
        "  videocompleted = False\n",
        "\n",
        "  start_sec = 0 \n",
        "  end_sec = start_sec + clip_duration\n",
        "\n",
        "  videotags = dict()\n",
        "\n",
        "  size = (512 , 256)\n",
        "\n",
        "  result = cv2.VideoWriter(\"/content/drive/MyDrive/Video_grouping_results/\" + videoname , \n",
        "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
        "                         int(frames_per_second/2), size)\n",
        "    \n",
        "  all_tagsinvideo = []\n",
        "  \n",
        "  while not videocompleted :\n",
        "\n",
        "    if end_sec > seconds :\n",
        "      videocompleted = True\n",
        "      \n",
        "      end_sec = seconds\n",
        "\n",
        "    # Initialize an EncodedVideo helper class\n",
        "    video = EncodedVideo.from_path(video_path)\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Load the desired clip\n",
        "    video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
        "\n",
        "\n",
        "\n",
        "    # Apply a transform to normalize the video input\n",
        "    try :\n",
        "      video_data = transform(video_data)\n",
        "\n",
        "    except: \n",
        "\n",
        "      continue\n",
        "\n",
        "    # Move the inputs to the desired device\n",
        "    inputs = video_data[\"video\"]\n",
        "    \n",
        "    normalten = inputs[1].permute((1,0, 2,3))\n",
        "\n",
        "    print(normalten.shape)\n",
        "\n",
        "    un = UnNormalize(mean ,std)\n",
        "\n",
        "    \n",
        "      \n",
        "    inputs = [i.to(device)[None, ...] for i in inputs]\n",
        "\n",
        "    \n",
        "    # Pass the input clip through the model\n",
        "    preds = model(inputs)\n",
        "\n",
        "    \n",
        "\n",
        "    # Get the predicted classes\n",
        "    post_act = torch.nn.Softmax(dim=1)\n",
        "\n",
        "    end = time.time()\n",
        "\n",
        "    print(\"Time taken \",end - start)\n",
        "\n",
        "\n",
        "    preds = post_act(preds)\n",
        "    pred_classes = preds.topk(k=10).indices\n",
        "\n",
        "    # Map the predicted classes to the label names\n",
        "    pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes[0]]\n",
        "\n",
        "    print(\"Clip Duration : {0} with start_sec at {1} and end_sec at {2}\".format(clip_duration,start_sec,end_sec))\n",
        "\n",
        "    print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
        "\n",
        "    videotags[round(start_sec,2)] = pred_class_names\n",
        "\n",
        "    for pred_c_n in pred_class_names :\n",
        "\n",
        "      if pred_c_n not in all_tagsinvideo :\n",
        "        all_tagsinvideo.append(pred_c_n)\n",
        "\n",
        "    start_sec += clip_duration \n",
        "    end_sec = (start_sec + clip_duration)\n",
        "\n",
        "\n",
        "    for tensor in normalten:\n",
        "      \n",
        "      img = un(tensor)\n",
        "\n",
        "      img = img.mul(255).byte()\n",
        "\n",
        "      img = img.cpu().numpy().transpose((1, 2, 0))\n",
        "    \n",
        "      # # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "      #image = np.clip(image, 0, 1)\n",
        "\n",
        "      #print(image.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      image = img[:, :,::-1].astype('uint8')\n",
        "\n",
        "      image = cv2.copyMakeBorder( image, 0, 0, 256, 0, cv2.BORDER_CONSTANT)\n",
        "\n",
        "      for i,text in enumerate(pred_class_names):\n",
        "        image = cv2.putText(image, text, (10, (i+1)*25 ) , cv2.FONT_HERSHEY_SIMPLEX, 0.5, \n",
        "                 (255,255,255), 1, cv2.LINE_AA)\n",
        "        \n",
        "      #print(image.shape)\n",
        "\n",
        "      # plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "      # plt.show() \n",
        "\n",
        "      result.write(image)\n",
        "\n",
        "  print(all_tagsinvideo)\n",
        "\n",
        "  tagsdict[videoname] = videotags\n",
        "\n",
        "\n",
        "\n",
        "  result.release()\n",
        "\n",
        "\n",
        "with open(\"tags.json\", \"w\") as outfile: \n",
        "  json.dump(tagsdict, outfile)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VideoName Video_22.mp4 :\n",
            "Total clip duration  60\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.8932244777679443\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 0 and end_sec at 2.1333333333333333\n",
            "Predicted labels: eating burger, dining, eating hotdog, eating doughnuts, celebrating, tasting food, auctioning, eating ice cream, eating cake, playing ukulele\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9100818634033203\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 2.1333333333333333 and end_sec at 4.266666666666667\n",
            "Predicted labels: dining, celebrating, eating burger, auctioning, drinking beer, tasting food, tasting beer, eating hotdog, drinking shots, singing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9158265590667725\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 4.266666666666667 and end_sec at 6.4\n",
            "Predicted labels: celebrating, dining, auctioning, pumping fist, eating burger, drinking beer, drinking shots, blowing out candles, singing, bartending\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9159483909606934\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 6.4 and end_sec at 8.533333333333333\n",
            "Predicted labels: celebrating, dancing macarena, pumping fist, singing, eating burger, krumping, dining, dancing gangnam style, auctioning, air drumming\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9276449680328369\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 8.533333333333333 and end_sec at 10.666666666666666\n",
            "Predicted labels: celebrating, singing, dancing gangnam style, dancing macarena, pumping fist, dining, krumping, zumba, counting money, eating burger\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.936699628829956\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 10.666666666666666 and end_sec at 12.799999999999999\n",
            "Predicted labels: auctioning, dining, celebrating, playing poker, eating burger, drinking beer, bartending, arm wrestling, tasting beer, singing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9438488483428955\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 12.799999999999999 and end_sec at 14.933333333333332\n",
            "Predicted labels: dining, celebrating, marching, shaking hands, waiting in line, playing trumpet, playing trombone, drinking beer, riding elephant, singing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9510335922241211\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 14.933333333333332 and end_sec at 17.066666666666666\n",
            "Predicted labels: eating spaghetti, dining, eating burger, kissing, hugging, eating chips, tasting food, cracking neck, sniffing, eating hotdog\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9481673240661621\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 17.066666666666666 and end_sec at 19.2\n",
            "Predicted labels: dining, eating spaghetti, eating burger, playing trumpet, peeling apples, celebrating, playing saxophone, setting table, tasting food, auctioning\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9621169567108154\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 19.2 and end_sec at 21.333333333333332\n",
            "Predicted labels: dining, eating burger, celebrating, playing poker, auctioning, eating spaghetti, holding snake, surfing crowd, tasting food, eating hotdog\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9727346897125244\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 21.333333333333332 and end_sec at 23.466666666666665\n",
            "Predicted labels: country line dancing, beatboxing, playing clarinet, tap dancing, celebrating, shaking hands, rock scissors paper, playing violin, dancing macarena, arm wrestling\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9838113784790039\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 23.466666666666665 and end_sec at 25.599999999999998\n",
            "Predicted labels: singing, dancing gangnam style, dancing macarena, finger snapping, playing ukulele, celebrating, beatboxing, playing recorder, busking, clapping\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  1.0205235481262207\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 25.599999999999998 and end_sec at 27.73333333333333\n",
            "Predicted labels: dancing macarena, dancing charleston, finger snapping, celebrating, dancing gangnam style, country line dancing, tap dancing, pumping fist, singing, swing dancing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  1.026501178741455\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 27.73333333333333 and end_sec at 29.866666666666664\n",
            "Predicted labels: celebrating, auctioning, dining, belly dancing, tango dancing, salsa dancing, sign language interpreting, singing, contact juggling, drinking beer\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  1.1501548290252686\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 29.866666666666664 and end_sec at 31.999999999999996\n",
            "Predicted labels: celebrating, dancing macarena, dining, singing, auctioning, eating burger, pumping fist, drinking beer, dancing gangnam style, beatboxing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  1.0056519508361816\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 31.999999999999996 and end_sec at 34.13333333333333\n",
            "Predicted labels: dining, eating burger, celebrating, tasting food, eating hotdog, tasting beer, auctioning, drinking beer, eating doughnuts, drinking shots\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9009976387023926\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 34.13333333333333 and end_sec at 36.266666666666666\n",
            "Predicted labels: making pizza, dining, making a sandwich, eating hotdog, tasting food, barbequing, eating burger, baking cookies, cooking chicken, cooking sausages\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9120292663574219\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 36.266666666666666 and end_sec at 38.4\n",
            "Predicted labels: making pizza, making a sandwich, baking cookies, tasting food, dining, cooking chicken, carving pumpkin, eating hotdog, making a cake, barbequing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9153287410736084\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 38.4 and end_sec at 40.53333333333333\n",
            "Predicted labels: eating hotdog, dining, eating burger, celebrating, making pizza, eating doughnuts, tasting food, eating chips, eating spaghetti, dancing macarena\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9100728034973145\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 40.53333333333333 and end_sec at 42.666666666666664\n",
            "Predicted labels: dining, eating hotdog, eating burger, eating spaghetti, tasting food, celebrating, eating chips, drinking shots, eating cake, tasting beer\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.916450023651123\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 42.666666666666664 and end_sec at 44.8\n",
            "Predicted labels: dining, tasting food, eating hotdog, eating burger, eating chips, celebrating, eating cake, blowing out candles, drinking shots, eating doughnuts\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.917607307434082\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 44.8 and end_sec at 46.93333333333333\n",
            "Predicted labels: dining, eating burger, tasting food, eating hotdog, celebrating, tasting beer, eating spaghetti, eating doughnuts, eating chips, drinking shots\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9355301856994629\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 46.93333333333333 and end_sec at 49.06666666666666\n",
            "Predicted labels: celebrating, dining, capoeira, auctioning, drinking, singing, eating burger, drinking beer, counting money, dancing macarena\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9862747192382812\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 49.06666666666666 and end_sec at 51.199999999999996\n",
            "Predicted labels: celebrating, dancing macarena, belly dancing, capoeira, singing, salsa dancing, zumba, stomping grapes, country line dancing, dancing gangnam style\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9701285362243652\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 51.199999999999996 and end_sec at 53.33333333333333\n",
            "Predicted labels: celebrating, dancing macarena, auctioning, waiting in line, singing, dining, country line dancing, drinking beer, salsa dancing, sign language interpreting\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9804608821868896\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 53.33333333333333 and end_sec at 55.46666666666666\n",
            "Predicted labels: celebrating, auctioning, dining, waiting in line, singing, belly dancing, giving or receiving award, country line dancing, dancing charleston, marching\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9790530204772949\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 55.46666666666666 and end_sec at 57.599999999999994\n",
            "Predicted labels: celebrating, braiding hair, fixing hair, dining, playing accordion, waiting in line, shaving head, getting a haircut, giving or receiving award, riding camel\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.9750163555145264\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 57.599999999999994 and end_sec at 59.73333333333333\n",
            "Predicted labels: celebrating, braiding hair, dining, fixing hair, tasting food, blowing out candles, tasting beer, giving or receiving award, holding snake, laughing\n",
            "torch.Size([32, 3, 256, 256])\n",
            "Time taken  0.5084893703460693\n",
            "Clip Duration : 2.1333333333333333 with start_sec at 59.73333333333333 and end_sec at 60\n",
            "Predicted labels: braiding hair, knitting, curling hair, holding snake, making jewelry, smoking, smoking hookah, fixing hair, tying knot (not on a tie), playing saxophone\n",
            "['eating burger', 'dining', 'eating hotdog', 'eating doughnuts', 'celebrating', 'tasting food', 'auctioning', 'eating ice cream', 'eating cake', 'playing ukulele', 'drinking beer', 'tasting beer', 'drinking shots', 'singing', 'pumping fist', 'blowing out candles', 'bartending', 'dancing macarena', 'krumping', 'dancing gangnam style', 'air drumming', 'zumba', 'counting money', 'playing poker', 'arm wrestling', 'marching', 'shaking hands', 'waiting in line', 'playing trumpet', 'playing trombone', 'riding elephant', 'eating spaghetti', 'kissing', 'hugging', 'eating chips', 'cracking neck', 'sniffing', 'peeling apples', 'playing saxophone', 'setting table', 'holding snake', 'surfing crowd', 'country line dancing', 'beatboxing', 'playing clarinet', 'tap dancing', 'rock scissors paper', 'playing violin', 'finger snapping', 'playing recorder', 'busking', 'clapping', 'dancing charleston', 'swing dancing', 'belly dancing', 'tango dancing', 'salsa dancing', 'sign language interpreting', 'contact juggling', 'making pizza', 'making a sandwich', 'barbequing', 'baking cookies', 'cooking chicken', 'cooking sausages', 'carving pumpkin', 'making a cake', 'capoeira', 'drinking', 'stomping grapes', 'giving or receiving award', 'braiding hair', 'fixing hair', 'playing accordion', 'shaving head', 'getting a haircut', 'riding camel', 'laughing', 'knitting', 'curling hair', 'making jewelry', 'smoking', 'smoking hookah', 'tying knot (not on a tie)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpKhghz05k84"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FSdFr6HQ-H7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EU_RpwIbqJX",
        "outputId": "29750897-79fe-42c2-e9c9-1c0ddbb3ba56"
      },
      "source": [
        "!pip install spacy "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8-wRzriGwBJ"
      },
      "source": [
        "listoftags = ['eating burger', 'dining', 'eating hotdog', 'eating doughnuts', 'celebrating', 'tasting food', \n",
        " 'auctioning', 'eating ice cream', 'eating cake', 'playing ukulele', 'drinking beer', 'tasting beer', \n",
        " 'drinking shots', 'singing', 'pumping fist', 'blowing out candles', 'bartending', 'dancing macarena', \n",
        " 'krumping', 'dancing gangnam style', 'air drumming', 'zumba', 'counting money', 'playing poker', \n",
        " 'arm wrestling', 'marching', 'shaking hands', 'waiting in line', 'playing trumpet', 'playing trombone', \n",
        " 'riding elephant', 'eating spaghetti', 'kissing', 'hugging', 'eating chips', 'cracking neck', 'sniffing', \n",
        " 'peeling apples', 'playing saxophone', 'setting table', 'holding snake', 'surfing crowd', 'country line dancing', \n",
        " 'beatboxing', 'playing clarinet', 'tap dancing', 'rock scissors paper', 'playing violin', 'finger snapping', \n",
        " 'playing recorder', 'busking', 'clapping', 'dancing charleston', 'swing dancing', 'belly dancing', 'tango dancing', \n",
        " 'salsa dancing', 'sign language interpreting', 'contact juggling', 'making pizza', 'making a sandwich', 'barbequing',\n",
        " 'baking cookies', 'cooking chicken', 'cooking sausages', 'carving pumpkin', 'making a cake', 'capoeira', 'drinking',\n",
        " 'stomping grapes', 'giving or receiving award', 'braiding hair', 'fixing hair', 'playing accordion', 'shaving head', \n",
        " 'getting a haircut', 'riding camel', \n",
        " 'laughing', 'knitting', 'curling hair', 'making jewelry', 'smoking', 'smoking hookah', 'tying knot (not on a tie)']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OeOvT3X4Crl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0FhUO9q4CoA",
        "outputId": "1399f298-fa5a-481c-b642-0b8d5f9ef7f8"
      },
      "source": [
        "!git clone https://github.com/PGCodehub/HVU-Dataset.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'HVU-Dataset' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUbN1Klg4Clo"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "TMOceazELkGo",
        "outputId": "3652fa92-4981-48b2-d26c-9e82ab194c49"
      },
      "source": [
        "csv = pd.read_csv(\"/content/HVU-Dataset/HVU_Tags_Categories_V1.0.csv\")\n",
        "\n",
        "csv.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tag</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>playing_trombone</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>playing_controller</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>photograph</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>recreation</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sitting</td>\n",
              "      <td>action</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Tag Category\n",
              "0    playing_trombone   action\n",
              "1  playing_controller   action\n",
              "2          photograph   action\n",
              "3          recreation   action\n",
              "4             sitting   action"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "rXOwPQeJ4Lsc",
        "outputId": "b066acfb-4b6a-47db-8b83-751cf653e4a0"
      },
      "source": [
        "df1 = csv.groupby('Category')['Tag'].apply(list).reset_index(name='Listoftags')\n",
        "\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Listoftags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>action</td>\n",
              "      <td>[playing_trombone, playing_controller, photogr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>attribute</td>\n",
              "      <td>[fun, beauty, leisure, human_hair_color, black...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>concept</td>\n",
              "      <td>[classical_music, music, electronics, technolo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>event</td>\n",
              "      <td>[summer, night, concert, vacation, wedding, ce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>object</td>\n",
              "      <td>[brass_instrument, musical_instrument, trumpet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Category                                         Listoftags\n",
              "0     action  [playing_trombone, playing_controller, photogr...\n",
              "1  attribute  [fun, beauty, leisure, human_hair_color, black...\n",
              "2    concept  [classical_music, music, electronics, technolo...\n",
              "3      event  [summer, night, concert, vacation, wedding, ce...\n",
              "4     object  [brass_instrument, musical_instrument, trumpet..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X19pB8J-Zta"
      },
      "source": [
        "def tokenizer(mylist):\n",
        "    tokenized_list=[]\n",
        "    for word in mylist:\n",
        "        if '_'  in word:\n",
        "            word = word.replace('_' , ' ').lower()\n",
        "            tokenized_list.append(word)\n",
        "      \n",
        "        else:\n",
        "            tokenized_list.append(word.lower())\n",
        "    return(tokenized_list)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxa5Zjjc4LpI"
      },
      "source": [
        "HUV_dataset = dict()\n",
        "\n",
        "for index, row in df1.iterrows():\n",
        "    \n",
        "    HUV_dataset[row['Category']] = tokenizer(row['Listoftags'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJmuA5HM4Lm9",
        "outputId": "8e1e3231-2767-4403-843f-19e6609b8b82"
      },
      "source": [
        "HUV_dataset.keys()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['action', 'attribute', 'concept', 'event', 'object', 'scene'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rimjg7ms4LkV",
        "outputId": "44d99bcd-16ff-46b8-a460-864295c044e3"
      },
      "source": [
        "if 'eating burger' in HUV_dataset['action']:\n",
        "  print(\"dsd\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dsd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUZYhqUVLkix"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ythMTzSf0KMj"
      },
      "source": [
        "#!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp9UuMN-Vt2B"
      },
      "source": [
        "nlp = spacy.load('en_core_web_lg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Bx9ztKzCV6"
      },
      "source": [
        "HUV_dataset_nlp = []\n",
        "\n",
        "for action in HUV_dataset['action']:\n",
        "\n",
        "  HUV_dataset_nlp.append(nlp(action))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-Ie-Jho3MTd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7DFaYILzCSV"
      },
      "source": [
        "# compute similarity    \n",
        "similarities = {}   \n",
        "for word in listoftags:\n",
        "    tok = nlp(word)\n",
        "    similarities[tok.text] ={}\n",
        "    for tok_ in HUV_dataset_nlp:\n",
        "\n",
        "        #print(tok_)\n",
        "\n",
        "        #tok_ = nlp(tok_)\n",
        "        similarities[tok.text].update({tok_.text:tok.similarity(tok_)})\n",
        "\n",
        "# sort\n",
        "top10 = lambda x: {k: v for k, v in sorted(similarities[x].items(), key=lambda item: item[1], reverse=True)[:10]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoRnEp9t5CBU"
      },
      "source": [
        "similarities[listoftags[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi-Y5wD671d_",
        "outputId": "b07beb6d-27c6-41c9-a21d-1ede8d81abda"
      },
      "source": [
        "top10(listoftags[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attending conference': 0.4368617391961273,\n",
              " 'celebrating': 1.0,\n",
              " 'cheering': 0.42758004722142734,\n",
              " 'country line dancing': 0.41783343037774123,\n",
              " 'decorating the christmas tree': 0.4156155066898929,\n",
              " 'gospel singing in church': 0.4311155152140683,\n",
              " 'making a cake': 0.3995945569998262,\n",
              " 'opening present': 0.40964339638496994,\n",
              " 'visiting the zoo': 0.4185037631464736,\n",
              " 'wrapping present': 0.3976307342569076}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "i1zP1xE471ak",
        "outputId": "65de9384-925c-48a3-e578-cdc87db92c58"
      },
      "source": [
        "listoftags[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'eating burger'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNyaueqB71X2",
        "outputId": "0b114be6-0c40-4fe7-a588-a435bb25220f"
      },
      "source": [
        "for tag in listoftags[:20]:\n",
        "\n",
        "  print(\"Tag \"+tag+ \" close Words :\")\n",
        "  print(top10(tag))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag eating burger close Words :\n",
            "{'eating burger': 1.0, 'eating hotdog': 0.8811544464160944, 'eating': 0.869451134611863, 'eating doughnuts': 0.8294750236838928, 'eating cake': 0.8262713836216452, 'eating spaghetti': 0.801321227023556, 'eating chips': 0.8006912498677948, 'eating watermelon': 0.7970364289951508, 'eating carrots': 0.7914155290191551, 'tasting food': 0.7191837070256192}\n",
            "Tag dining close Words :\n",
            "{'dining': 1.0, 'outdoor recreation': 0.5894881706918668, 'setting table': 0.5638255741853612, 'tasting food': 0.5483881532989527, 'moving furniture': 0.5239409713768117, 'painting furniture': 0.5160987028950328, 'cooking sausages not on barbeque ': 0.5160624759757587, 'home roasting coffee': 0.5079771866205971, 'washing dishes': 0.4997844257994517, 'making sushi': 0.49978076839342145}\n",
            "Tag eating hotdog close Words :\n",
            "{'eating hotdog': 1.0, 'eating burger': 0.8811544464160944, 'eating': 0.84430319015075, 'eating doughnuts': 0.8316567836602358, 'eating spaghetti': 0.8032764664890255, 'eating watermelon': 0.8005396353400149, 'eating cake': 0.7897680813606308, 'eating carrots': 0.7765323101462784, 'eating chips': 0.7716615797574677, 'eating ice cream': 0.6925144006958349}\n",
            "Tag eating doughnuts close Words :\n",
            "{'eating doughnuts': 1.0, 'eating cake': 0.8553463536273058, 'eating': 0.8469160831869916, 'eating hotdog': 0.8316567836602358, 'eating burger': 0.8294750236838928, 'eating watermelon': 0.7983376504044185, 'eating chips': 0.7871787909791701, 'eating carrots': 0.7836787505563313, 'eating spaghetti': 0.7657440604200128, 'eating ice cream': 0.7449602069443275}\n",
            "Tag celebrating close Words :\n",
            "{'celebrating': 1.0, 'attending conference': 0.4368617391961273, 'gospel singing in church': 0.4311155152140683, 'cheering': 0.42758004722142734, 'visiting the zoo': 0.4185037631464736, 'country line dancing': 0.41783343037774123, 'decorating the christmas tree': 0.4156155066898929, 'opening present': 0.40964339638496994, 'making a cake': 0.3995945569998262, 'wrapping present': 0.3976307342569076}\n",
            "Tag tasting food close Words :\n",
            "{'tasting food': 1.0, 'tasting wine': 0.8444880010159841, 'tasting beer': 0.8389905900805027, 'eating burger': 0.7191837070256192, 'eating cake': 0.7005767828688717, 'opening bottle not wine ': 0.6891693032474383, 'opening wine bottle': 0.6863170535681545, 'eating': 0.6857790256875596, 'cooking sausages not on barbeque ': 0.6780391799526068, 'eating watermelon': 0.6601618005705742}\n",
            "Tag auctioning close Words :\n",
            "{'auctioning': 1.0, 'person collecting garbage': 0.2788410723674714, 'counting money': 0.2784050121972451, 'bulldozing': 0.2677232387909032, 'playing monopoly': 0.24293448289220712, 'putting on sari': 0.23495863866290015, 'tossing coin': 0.2300996170765413, 'making jewelry': 0.2259049379720155, 'assembling bicycle': 0.22483164031590927, 'celebrating': 0.22411833092372732}\n",
            "Tag eating ice cream close Words :\n",
            "{'eating ice cream': 1.0, 'eating cake': 0.8170134516787723, 'ice swimming': 0.7584926460426595, 'eating watermelon': 0.7538287084896197, 'eating doughnuts': 0.7449602069443275, 'carving ice': 0.7412136402111521, 'eating': 0.7355297496903516, 'ice skating': 0.7318817842149035, 'eating chips': 0.7208852948588945, 'ice climbing': 0.7187605301527052}\n",
            "Tag eating cake close Words :\n",
            "{'eating cake': 1.0, 'eating doughnuts': 0.8553463536273058, 'eating': 0.8518786010680666, 'eating burger': 0.8262713836216452, 'eating watermelon': 0.8226471208545375, 'eating ice cream': 0.8170134516787723, 'eating spaghetti': 0.7985037884454486, 'eating chips': 0.7968512739374998, 'eating hotdog': 0.7897680813606308, 'eating carrots': 0.788764157520116}\n",
            "Tag playing ukulele close Words :\n",
            "{'playing ukulele': 1.0, 'playing guitar': 0.8874277611842352, 'playing harmonica': 0.8809070546485492, 'playing saxophone': 0.8593333783919388, 'playing harp': 0.8528961840267894, 'playing violin': 0.8528546309035474, 'playing piano': 0.8485962526583752, 'playing trombone': 0.8352661716656926, 'playing clarinet': 0.8345445867855659, 'playing accordion': 0.8313575055667642}\n",
            "Tag drinking beer close Words :\n",
            "{'drinking': 0.9137542585538543, 'pouring beer': 0.8753380805993143, 'tasting beer': 0.8572776014958441, 'drinking shots': 0.7543967516145955, 'playing beer pong': 0.7452593740546252, 'opening bottle not wine ': 0.6992114273964929, 'opening wine bottle': 0.6936023991398464, 'tasting wine': 0.6769224380160601, 'tasting food': 0.6713713709104918, 'sipping cup': 0.6577174864047535}\n",
            "Tag tasting beer close Words :\n",
            "{'tasting beer': 1.0, 'tasting wine': 0.8933528516857384, 'pouring beer': 0.8414021428460738, 'tasting food': 0.8389905900805027, 'opening wine bottle': 0.7667299896264779, 'opening bottle not wine ': 0.7415211316821001, 'playing beer pong': 0.6840482613235913, 'drinking': 0.6591217317226006, 'sipping cup': 0.618157228874375, 'home roasting coffee': 0.5809239897383885}\n",
            "Tag drinking shots close Words :\n",
            "{'drinking shots': 1.0, 'drinking': 0.8036343369172705, 'shot put': 0.682545150024795, 'pouring beer': 0.6471507695023921, 'playing beer pong': 0.6043166613375255, 'opening bottle not wine ': 0.5922510257493759, 'shooting': 0.5874237127282493, 'eating ice cream': 0.5856387906069578, 'tasting beer': 0.5804842784273708, 'eating': 0.5689272716137589}\n",
            "Tag singing close Words :\n",
            "{'singing': 1.0, 'gospel singing in church': 0.7245672872923762, 'playing piano': 0.6374546832655095, 'folk dance': 0.6367723877576389, 'playing harmonica': 0.6210166058814147, 'playing harp': 0.6146462311178521, 'playing guitar': 0.6128619346803447, 'playing ukulele': 0.6087643316221104, 'playing flute': 0.6075351486770096, 'playing trumpet': 0.5996391529169939}\n",
            "Tag pumping fist close Words :\n",
            "{'pumping fist': 1.0, 'pumping gas': 0.6930439330387469, 'shaking hands': 0.6201920550818512, 'drumming fingers': 0.5990480571981903, 'sticking tongue out': 0.5909369283249727, 'slapping': 0.5902988153204255, 'shaking head': 0.5848344612137938, 'stretching arm': 0.5840329211111056, 'throwing water balloon': 0.5774534736995515, 'licking': 0.5734292403333636}\n",
            "Tag blowing out candles close Words :\n",
            "{'blowing out candles': 1.0, 'blowing glass': 0.7667471497976958, 'blowing leaves': 0.7472170584172443, 'blowing nose': 0.6872434613577377, 'blowing bubble gum': 0.6649324315958324, 'throwing water balloon': 0.6572147628520292, 'making bubbles': 0.6475276543324701, 'sticking tongue out': 0.6339314522396463, 'decorating the christmas tree': 0.6230917695417572, 'waving hand': 0.6178177585782696}\n",
            "Tag bartending close Words :\n",
            "{'bartending': 1.0, 'cooking': 0.35435999787287337, 'pouring beer': 0.35265955000610283, 'dancing charleston': 0.34819047811899584, 'skydiving': 0.34095639554638707, 'breakdancing': 0.34088979800425234, 'tasting beer': 0.3402071595615031, 'drinking': 0.320757522833975, 'doing kickboxing': 0.31475789611861804, 'busking': 0.3129255153732385}\n",
            "Tag dancing macarena close Words :\n",
            "{'dancing macarena': 1.0, 'tango dancing': 0.7857865956543868, 'jumpstyle dancing': 0.7619133219981803, 'salsa dancing': 0.7493730803163816, 'dance': 0.7226118906017436, 'dancing ballet': 0.7221716880611162, 'swing dancing': 0.6829155398444982, 'dancing charleston': 0.6800130751171786, 'dancing gangnam style': 0.6747681913390873, 'tap dancing': 0.6667742065158263}\n",
            "Tag krumping close Words :\n",
            "{'krumping': 1.0, 'breakdancing': 0.6272965254510698, 'jumpstyle dancing': 0.47318423517331176, 'beatboxing': 0.4614942469940992, 'parkour': 0.4427824287405682, 'capoeira': 0.43369867730252704, 'dancing macarena': 0.41958079044008706, 'slacklining': 0.41676385447279185, 'cumbia': 0.39718458598486006, 'hula hooping': 0.3946512794331439}\n",
            "Tag dancing gangnam style close Words :\n",
            "{'dancing gangnam style': 1.0, 'dance': 0.7200842930955839, 'tango dancing': 0.7024691715921073, 'swing dancing': 0.6934194635288571, 'dancing ballet': 0.692148982793206, 'salsa dancing': 0.6801745087652777, 'jumpstyle dancing': 0.6761795695726681, 'dancing macarena': 0.6747681913390873, 'modern dance': 0.671389204451268, 'belly dancing': 0.6673560256459528}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS0ZykTk71U7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaFcghw771R4"
      },
      "source": [
        "HUV_dataset_objects_nlp = []\n",
        "\n",
        "for objet in HUV_dataset['object']:\n",
        "\n",
        "  HUV_dataset_objects_nlp.append(nlp(objet))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd4CgD6GzCOB"
      },
      "source": [
        "# compute similarity    \n",
        "objsimilarities = {}   \n",
        "for word in listoftags:\n",
        "    tok = nlp(word)\n",
        "    objsimilarities[tok.text] ={}\n",
        "    for tok_ in HUV_dataset_objects_nlp:\n",
        "\n",
        "        #print(tok_)\n",
        "\n",
        "        #tok_ = nlp(tok_)\n",
        "        objsimilarities[tok.text].update({tok_.text:tok.similarity(tok_)})\n",
        "\n",
        "# sort\n",
        "objtop10 = lambda x: {k: v for k, v in sorted(objsimilarities[x].items(), key=lambda item: item[1], reverse=True)[:10]}\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWlJGG2L6qXU",
        "outputId": "9c7eaa42-de8c-4a6f-df77-d4d4cecd9b81"
      },
      "source": [
        "for tag in listoftags[:20]:\n",
        "\n",
        "  print(\"Tag \"+tag+ \" close Words :\")\n",
        "  print(objtop10(tag))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tag eating burger close Words :\n",
            "{'eating apple': 0.7782340749061656, 'pizza cheese': 0.7524688047375979, 'cheese pizza': 0.7524688047375979, 'hamburger': 0.7506465414685103, 'sandwich': 0.7264423649902352, 'food': 0.7243706335953234, 'pizza': 0.7207653355035516, 'meat': 0.7173273142192711, 'steak': 0.7169213441225496, 'cheeseburger': 0.715374084132162}\n",
            "Tag dining close Words :\n",
            "{'dining table': 0.8943436908585392, 'outdoor furniture': 0.6757364930709249, 'outdoor grill': 0.6331220513976582, 'coffee table': 0.6147673353753536, 'fireplace': 0.6067397061272719, 'space bar': 0.6024288461258814, 'balcony': 0.5912305873157151, 'furniture': 0.5866282393818751, 'table': 0.543305178715405, 'kitchen appliance': 0.5397080159833199}\n",
            "Tag eating hotdog close Words :\n",
            "{'eating apple': 0.7355186471776982, 'hamburger': 0.7008172388508687, 'snack': 0.6717127558157777, 'pizza cheese': 0.6648871629200265, 'cheese pizza': 0.6648871629200265, 'meat': 0.664863347872518, 'pizza': 0.6579862617104214, 'cheeseburger': 0.6554858187755658, 'food': 0.654054099084115, 'sandwich': 0.6500202761321695}\n",
            "Tag eating doughnuts close Words :\n",
            "{'eating apple': 0.769411765170106, 'snack': 0.6753558304359653, 'bread': 0.6599026494536786, 'chocolate cake': 0.6595780226360078, 'frozen dessert': 0.6554082576351101, 'pizza cheese': 0.6554047679567913, 'cheese pizza': 0.6554047679567913, 'food': 0.6521431030825052, 'dessert': 0.6514317773957187, 'fried egg': 0.6455532332458719}\n",
            "Tag celebrating close Words :\n",
            "{'birthday cake': 0.5022782602909391, 'wedding ceremony supply': 0.45439292071512005, 'concert grand': 0.44659554785418093, 'gift': 0.4086488617963192, 'flag of the united states': 0.37752432777653383, 'wedding dress': 0.3474580721149715, 'christmas decoration': 0.3428597344930861, 'dance dress': 0.339083548829313, 'annual plant': 0.33500823015811887, 'vigil light': 0.3324569518434326}\n",
            "Tag tasting food close Words :\n",
            "{'food': 0.8700830613257642, 'wine': 0.7214942961931917, 'dessert': 0.6745021662380832, 'drink': 0.6685875879702091, 'beer cocktail': 0.6666407635212273, 'eating apple': 0.6611247622753951, 'frozen dessert': 0.6601951311856011, 'pizza cheese': 0.6593134001660004, 'cheese pizza': 0.6593134001660004, 'meat': 0.6590347927722129}\n",
            "Tag auctioning close Words :\n",
            "{'cash': 0.2610619732828167, 'scrap': 0.24449744578947413, 'vintage clothing': 0.2195904002468946, 'artifact': 0.20464095279678954, 'antique': 0.20102033321691698, 'pawn': 0.19933602512372461, 'stocking': 0.19701339145610627, 'livestock': 0.19665064232939297, 'television set': 0.1956316829764005, 'artwork': 0.1881899800117627}\n",
            "Tag eating ice cream close Words :\n",
            "{'ice cream': 0.9327302584652498, 'ice cream cone': 0.8747996484438639, 'cream': 0.8389254875709233, 'ice': 0.8303539635689612, 'cream cheese': 0.8220775874113364, 'whipped cream': 0.7955501665169987, 'frozen dessert': 0.7782743794785456, 'shaving cream': 0.7498104399002354, 'sea ice': 0.7483774146242262, 'eating apple': 0.7477102054144458}\n",
            "Tag eating cake close Words :\n",
            "{'cake': 0.8468609704923543, 'chocolate cake': 0.8447522166779816, 'sugar cake': 0.8212967491094384, 'eating apple': 0.8184501125044243, 'birthday cake': 0.7741893597655946, 'flourless chocolate cake': 0.7689941470101902, 'dessert': 0.7667056257310828, 'chocolate': 0.7405899224075044, 'chocolate brownie': 0.7378846702643536, 'frozen dessert': 0.7368999334434819}\n",
            "Tag playing ukulele close Words :\n",
            "{'guitar': 0.7517790520027556, 'acoustic guitar': 0.7175433752174135, 'banjo': 0.7112092250149894, 'bass guitar': 0.6972551797686591, 'mandolin': 0.6908366937119697, 'bass fiddle': 0.6846025722818054, 'piano': 0.6754763149497364, 'harmonica': 0.6691579013289393, 'acoustic electric guitar': 0.6664200445604235, 'violin': 0.6556100762355609}\n",
            "Tag drinking beer close Words :\n",
            "{'beer': 0.9233678606842708, 'drink': 0.8509101037265268, 'beer cocktail': 0.8446543592445975, 'beer glass': 0.8287507715865222, 'drinking water': 0.8118475762096947, 'wheat beer': 0.7598418702158146, 'alcoholic beverage': 0.7532033366177595, 'soft drink': 0.7156287462673906, 'carbonated soft drinks': 0.7054289032885056, 'non alcoholic beverage': 0.7027788637113086}\n",
            "Tag tasting beer close Words :\n",
            "{'beer': 0.9089678591425756, 'beer cocktail': 0.845946791766701, 'beer glass': 0.804724948945788, 'wine': 0.7847936673930893, 'wheat beer': 0.7809172975947651, 'drink': 0.7411926650901312, 'wine glass': 0.7210296723513182, 'red wine': 0.7005408711994097, 'carbonated soft drinks': 0.6748236664111348, 'alcoholic beverage': 0.6697856184495002}\n",
            "Tag drinking shots close Words :\n",
            "{'drinking water': 0.739783560206344, 'drink': 0.7042449034257028, 'soft drink': 0.6260114269299691, 'beer glass': 0.605389487601604, 'beer cocktail': 0.6024861252003472, 'beer': 0.5885728713680966, 'carbonated soft drinks': 0.5562616890428393, 'bottled water': 0.545731711576875, 'bottle': 0.5440786338037306, 'alcoholic beverage': 0.5323111918722679}\n",
            "Tag singing close Words :\n",
            "{'singer': 0.6716192395030564, 'folk dancer': 0.5788911502255494, 'piano': 0.5624567039714765, 'acoustic guitar': 0.5509650823958946, 'guitar': 0.5301221248762203, 'musical keyboard': 0.5253436272138124, 'musical instrument': 0.5240241133997445, 'dance dress': 0.5126900970276876, 'musician': 0.49533959823001894, 'harmonica': 0.4945601868191287}\n",
            "Tag pumping fist close Words :\n",
            "{'mouth': 0.5593603261899119, 'finger': 0.5550832601874911, 'gas pump': 0.5331492827739905, 'hand drum': 0.5228655229163635, 'hot air balloon': 0.5126075180021965, 'thumb': 0.5068048335914329, 'power shovel': 0.48802385832109996, 'hammer': 0.48751903432701404, 'power drill': 0.48690958449193505, 'hand': 0.47968199780020465}\n",
            "Tag blowing out candles close Words :\n",
            "{'candle': 0.713152917160241, 'hand glass': 0.619957152893628, 'christmas lights': 0.6160365559602446, 'hot air balloon': 0.5894987016234486, 'smoke': 0.5796738933899446, 'wood burning stove': 0.5684807149719994, 'air bubble': 0.5643674374124071, 'street light': 0.560768785427583, 'hand': 0.5575680407416871, 'cut flowers': 0.549982439718726}\n",
            "Tag bartending close Words :\n",
            "{'bartender': 0.6106230489770786, 'beer cocktail': 0.43612187184695433, 'cocktail': 0.422867465522874, 'alcoholic beverage': 0.40883555997042603, 'chef': 0.3997135962708395, 'waiter': 0.3833119406097955, 'barware': 0.38202020973614004, 'cocktail garnish': 0.373322840375247, 'non alcoholic beverage': 0.34811669373624937, 'champagne stemware': 0.3382128504723969}\n",
            "Tag dancing macarena close Words :\n",
            "{'dance dress': 0.6028645152386202, 'ballet dancer': 0.5791086324127367, 'dancer': 0.5612860388153135, 'folk dancer': 0.5272430453968789, 'ballet skirt': 0.4504093761026234, 'square dancer': 0.44822364659416514, 'jungle gym': 0.3889679082554455, 'clown': 0.38592792953584426, 'leotard': 0.3814606718354951, 'piano': 0.3713016809510941}\n",
            "Tag krumping close Words :\n",
            "{'hip': 0.31270671369142655, 'perico': 0.3115790212934857, 'trapeze': 0.3091551033762852, 'aerialist': 0.3083242047992387, 'unicyclist': 0.2986280215001198, 'skateboarder': 0.28085346607737405, 'leotard': 0.2758672009236087, 'juggler': 0.26777025817369826, 'choreographer': 0.26395017141727484, 'plimsoll': 0.2624205296827225}\n",
            "Tag dancing gangnam style close Words :\n",
            "{'dance dress': 0.704398918644795, 'folk dancer': 0.5891088162518409, 'ballet dancer': 0.5725253883535631, 'dancer': 0.5484313219133453, 'ballet skirt': 0.5218592253291608, 'square dancer': 0.4965222820727688, 'cocktail dress': 0.4861191264330554, 'dress': 0.4705336786126492, 'dress shirt': 0.46199097440827275, 'costume': 0.4609483439630951}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifLbzraa640w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}